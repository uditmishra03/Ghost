#
name: CI-CD

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:


concurrency:
  group: ci-cd-${{ github.ref }}
  cancel-in-progress: true

env:
  APP_NAME: ghost-app
  AWS_REGION: us-east-1
  ECR_REPO: ghost-app
  SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
  SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

jobs:
  prepare:
    name: Prepare metadata
    runs-on: [ self-hosted, devops-runner ]
    outputs:
      image_tag: ${{ steps.meta.outputs.image_tag }}
      short_sha: ${{ steps.meta.outputs.short_sha }}
    steps:
    - uses: actions/checkout@v4
    - id: meta
      run: |
        SHORT_SHA=$(echo "${GITHUB_SHA}" | cut -c1-7)
        echo "short_sha=${SHORT_SHA}" >> $GITHUB_OUTPUT
        echo "image_tag=${SHORT_SHA}" >> $GITHUB_OUTPUT

  sonarqube:
    name: SonarQube Analysis
    needs: prepare
    runs-on: [ self-hosted, devops-runner ]
    timeout-minutes: 15
    steps:
    - uses: actions/checkout@v4
      with:
        # Fetch more history for better incremental analysis
        fetch-depth: 0
    - name: SonarQube Scan (Community Edition)
      uses: sonarsource/sonarqube-scan-action@v2
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
      with:
        args: >
          -Dsonar.projectKey=ghost-app -Dsonar.sources=ghost,apps -Dsonar.exclusions=**/node_modules/**,**/dist/**,**/coverage/**,**/build/**,**/public/**,**/*.min.js,**/*.bundle.js -Dsonar.scanner.skipUnchanged=true -Dsonar.scanner.skipUnchangedFiles=true -Dsonar.scm.provider=git -Dsonar.qualitygate.wait=true -Dsonar.qualitygate.timeout=300 -Dsonar.host.url=${{ secrets.SONAR_HOST_URL }} -Dsonar.login=${{ secrets.SONAR_TOKEN }}

  build_push:
    name: Build & Push Image
    needs: [ prepare, sonarqube ]
    runs-on: [ self-hosted, devops-runner ]
    env:
      IMAGE_TAG: ${{ needs.prepare.outputs.image_tag }}
    steps:
    - uses: actions/checkout@v4
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
    - name: Set REPO_URI
      run: echo "REPO_URI=${{ steps.login-ecr.outputs.registry }}/${ECR_REPO}" >> $GITHUB_ENV
    - name: Sanity check
      run: |
        echo "IMAGE_TAG=${IMAGE_TAG}"
        test -n "${IMAGE_TAG}" || { echo "IMAGE_TAG is empty"; exit 1; }
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    - name: Carry forward :previous
      run: |
        docker pull "${REPO_URI}:latest" || true
        docker tag  "${REPO_URI}:latest" "${REPO_URI}:previous" || true
        docker push "${REPO_URI}:previous" || true
    - name: Build and Push with Cache
      run: |
        docker buildx create --name ci-builder --use --driver docker-container || true
        docker buildx inspect --bootstrap
        docker buildx build \
          --file .docker/Dockerfile \
          --cache-from=type=registry,ref=${REPO_URI}:buildcache \
          --cache-to=type=registry,ref=${REPO_URI}:buildcache,mode=max \
          -t ${REPO_URI}:latest \
          -t ${REPO_URI}:${IMAGE_TAG} \
          --push \
          .
  deploy_staging:
    name: Deploy to Staging
    needs: build_push
    runs-on: [ self-hosted, devops-runner ]
    steps:
    - uses: actions/checkout@v4
    - name: SSH into staging & deploy
      env:
        STAGING_HOST: ${{ secrets.STAGING_HOST }}
        STAGING_SSH_USER: ${{ secrets.STAGING_SSH_USER }}
        STAGING_SSH_KEY: ${{ secrets.STAGING_SSH_KEY }}
      run: |
        echo "${STAGING_SSH_KEY}" | tr -d '\r' > key_staging.pem
        chmod 600 key_staging.pem

        # Create ghost directory on staging server
        ssh -o StrictHostKeyChecking=no -i key_staging.pem ${STAGING_SSH_USER}@${STAGING_HOST} "mkdir -p ~/ghost"

        # Copy required files to staging server
        scp -i key_staging.pem -o StrictHostKeyChecking=no deploy/docker-compose.staging.yml ${STAGING_SSH_USER}@${STAGING_HOST}:~/ghost/docker-compose.staging.yml
        scp -i key_staging.pem -o StrictHostKeyChecking=no config.production.json ${STAGING_SSH_USER}@${STAGING_HOST}:~/ghost/config.production.json
        ssh -o StrictHostKeyChecking=no -i key_staging.pem ${STAGING_SSH_USER}@${STAGING_HOST} <<'EOS'
        set -euo pipefail

        # Install required tools if missing
        echo "Checking and installing required tools..."

        # Install Docker if not present
        if ! command -v docker &> /dev/null; then
          echo "Docker not found, installing..."
          sudo apt update -qq
          sudo apt install -y docker.io
          sudo systemctl start docker
          sudo systemctl enable docker
          sudo usermod -aG docker ubuntu
          # Apply group changes for current session
          newgrp docker || true
        fi

        # Install Docker Compose if not present
        if ! command -v docker-compose &> /dev/null; then
          echo "Docker Compose not found, installing..."
          sudo curl -L "https://github.com/docker/compose/releases/download/v2.21.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
          sudo chmod +x /usr/local/bin/docker-compose
        fi

        # Check if AWS CLI is installed, install if missing
        if ! command -v aws &> /dev/null; then
          echo "AWS CLI not found, installing..."
          curl -s "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip -q awscliv2.zip
          sudo ./aws/install
          rm -rf aws awscliv2.zip
        fi

        # Configure AWS CLI if not configured
        if [ ! -f ~/.aws/credentials ]; then
          echo "Configuring AWS CLI..."
          mkdir -p ~/.aws
          aws configure set aws_access_key_id "${{ secrets.AWS_ACCESS_KEY_ID }}"
          aws configure set aws_secret_access_key "${{ secrets.AWS_SECRET_ACCESS_KEY }}"
          aws configure set region us-east-1
          aws configure set output json
        fi

        REGION="us-east-1"
        ACCOUNT_ID=$(aws sts get-caller-identity --query 'Account' --output text)
        echo "Account ID: $ACCOUNT_ID"

        echo "Logging into ECR..."
        aws ecr get-login-password --region "$REGION" | docker login --username AWS --password-stdin "${ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com"

        echo "Changing to ghost directory..."
        cd ~/ghost
        pwd
        ls -la

        echo "Setting up Ghost content directory..."
        mkdir -p content
        sudo chown -R 1000:1000 content

        echo "Setting environment variables..."
        export AWS_ACCOUNT_ID="$ACCOUNT_ID"

        echo "Pulling images..."
        docker-compose -f docker-compose.staging.yml pull

        echo "Starting containers..."
        docker-compose -f docker-compose.staging.yml up -d

        echo "Checking container status..."
        docker-compose -f docker-compose.staging.yml ps
        docker ps -a

        echo "Cleaning up unused images..."
        docker image prune -f
        EOS

  smoke_test_staging:
    name: Smoke Test Staging
    needs: deploy_staging
    runs-on: [ self-hosted, devops-runner ]
    steps:
    - name: Check staging URL
      env:
        STAGING_HOST: ${{ secrets.STAGING_HOST }}
        STAGING_SSH_USER: ${{ secrets.STAGING_SSH_USER }}
        STAGING_SSH_KEY: ${{ secrets.STAGING_SSH_KEY }}
      run: |
        # First check if containers are running on staging server
        echo "${STAGING_SSH_KEY}" | tr -d '\r' > key_staging.pem
        chmod 600 key_staging.pem

        echo "=== Checking Docker containers on staging server ==="
        ssh -o StrictHostKeyChecking=no -i key_staging.pem ${STAGING_SSH_USER}@${STAGING_HOST} <<'EOS'
        echo "Docker containers status:"
        docker ps -a
        echo ""
        echo "Docker compose services status:"
        cd ~/ghost && docker-compose -f docker-compose.staging.yml ps
        echo ""
        echo "Checking if port 80 is listening:"
        sudo netstat -tlnp | grep :80 || echo "Port 80 not listening"
        EOS

        echo "=== Testing HTTP connectivity ==="
        for i in {1..30}; do
          code=$(curl -s -o /dev/null -w "%{http_code}" --connect-timeout 5 "${{ secrets.STAGING_HEALTH_URL }}" 2>/dev/null || echo "000")
          echo "Attempt $i => HTTP $code"
          if [ "$code" = "200" ]; then 
            echo "✅ Staging server is healthy!"
            exit 0
          elif [ "$code" = "000" ]; then
            echo "⚠️ Connection refused - checking server status..."
            break
          fi
          sleep 2
        done

        echo "❌ Health check failed. Getting more diagnostics..."
        ssh -o StrictHostKeyChecking=no -i key_staging.pem ${STAGING_SSH_USER}@${STAGING_HOST} <<'EOS'
        echo "=== Container logs ==="
        cd ~/ghost && docker-compose -f docker-compose.staging.yml logs --tail=50
        EOS
        exit 1

  deploy_production:
    name: Deploy to Production
    needs: smoke_test_staging
    runs-on: [ self-hosted, devops-runner ]
    environment:
      name: production
    steps:
    - uses: actions/checkout@v4
    - name: SSH into production & deploy
      env:
        PROD_HOST: ${{ secrets.PROD_HOST }}
        PROD_SSH_USER: ${{ secrets.PROD_SSH_USER }}
        PROD_SSH_KEY: ${{ secrets.PROD_SSH_KEY }}
      run: |
        echo "${PROD_SSH_KEY}" | tr -d '\r' > key_prod.pem
        chmod 600 key_prod.pem

        # Create ghost directory on production server
        ssh -o StrictHostKeyChecking=no -i key_prod.pem ${PROD_SSH_USER}@${PROD_HOST} "mkdir -p ~/ghost"

        # Copy required files to production server
        scp -i key_prod.pem -o StrictHostKeyChecking=no deploy/docker-compose.production.yml ${PROD_SSH_USER}@${PROD_HOST}:~/ghost/docker-compose.production.yml
        scp -i key_prod.pem -o StrictHostKeyChecking=no config.production.json ${PROD_SSH_USER}@${PROD_HOST}:~/ghost/config.production.json
        ssh -o StrictHostKeyChecking=no -i key_prod.pem ${PROD_SSH_USER}@${PROD_HOST} <<'EOS'
        set -euo pipefail

        # Install required tools if missing
        echo "Checking and installing required tools..."

        # Install Docker if not present  
        if ! command -v docker &> /dev/null; then
          echo "Docker not found, installing..."
          sudo apt update -qq
          sudo apt install -y docker.io
          sudo systemctl start docker
          sudo systemctl enable docker
          sudo usermod -aG docker ubuntu
          # Apply group changes for current session
          newgrp docker || true
        fi

        # Install Docker Compose if not present
        if ! command -v docker-compose &> /dev/null; then
          echo "Docker Compose not found, installing..."
          sudo curl -L "https://github.com/docker/compose/releases/download/v2.21.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
          sudo chmod +x /usr/local/bin/docker-compose
        fi

        # Check if AWS CLI is installed, install if missing
        if ! command -v aws &> /dev/null; then
          echo "AWS CLI not found, installing..."
          curl -s "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip -q awscliv2.zip
          sudo ./aws/install
          rm -rf aws awscliv2.zip
        fi

        # Configure AWS CLI if not configured
        if [ ! -f ~/.aws/credentials ]; then
          echo "Configuring AWS CLI..."
          mkdir -p ~/.aws
          aws configure set aws_access_key_id "${{ secrets.AWS_ACCESS_KEY_ID }}"
          aws configure set aws_secret_access_key "${{ secrets.AWS_SECRET_ACCESS_KEY }}"
          aws configure set region us-east-1
          aws configure set output json
        fi

        REGION="us-east-1"
        ACCOUNT_ID=$(aws sts get-caller-identity --query 'Account' --output text)
        echo "Account ID: $ACCOUNT_ID"

        echo "Logging into ECR..."
        aws ecr get-login-password --region "$REGION" | docker login --username AWS --password-stdin "${ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com"

        echo "Changing to ghost directory..."
        cd ~/ghost
        pwd
        ls -la

        echo "Setting up Ghost content directory..."
        mkdir -p content
        sudo chown -R 1000:1000 content

        echo "Setting environment variables..."
        export AWS_ACCOUNT_ID="$ACCOUNT_ID"

        echo "Pulling images..."
        docker-compose -f docker-compose.production.yml pull

        echo "Starting containers..."
        docker-compose -f docker-compose.production.yml up -d

        echo "Checking container status..."
        docker-compose -f docker-compose.production.yml ps
        docker ps -a

        echo "Cleaning up unused images..."
        docker image prune -f
        EOS
